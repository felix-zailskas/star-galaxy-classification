{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "from model import UNet, UNetWithGradCAM\n",
    "from utils.data_loading import BuildingsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetWithGradCAM(UNet(5, 3))\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "# Load and preprocess the test dataset\n",
    "DATA_DIR = \"../data/\"\n",
    "x_test_dir = os.path.join(DATA_DIR, \"test/\")\n",
    "\n",
    "test_dataset = BuildingsDataset(x_test_dir)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred, class_label):\n",
    "    true_positive = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "    false_positive = np.sum((y_true != class_label) & (y_pred == class_label))\n",
    "    \n",
    "    if true_positive + false_positive == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_positive)\n",
    "\n",
    "def recall(y_true, y_pred, class_label):\n",
    "    true_positive = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "    false_negative = np.sum((y_true == class_label) & (y_pred != class_label))\n",
    "    \n",
    "    if true_positive + false_negative == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "\n",
    "def f1_score(y_true, y_pred, class_label):\n",
    "    p = precision(y_true, y_pred, class_label)\n",
    "    r = recall(y_true, y_pred, class_label)\n",
    "    \n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "    return 2 * (p * r) / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [0.0, 0.0, 0.0]\n",
    "recall_scores = [0.0, 0.0, 0.0]\n",
    "precision_scores = [0.0, 0.0, 0.0]\n",
    "\n",
    "nums = [0, 0, 0]\n",
    "\n",
    "for image, gt_mask in test_dataset:\n",
    "    x_tensor = torch.from_numpy(image).to(device).unsqueeze(0)\n",
    "    x_tensor = x_tensor.permute(0, 3, 1, 2).float().to(device)\n",
    "    # Predict test image\n",
    "    pred_mask = model(x_tensor)\n",
    "    tensor_to_detach = pred_mask[\n",
    "        0\n",
    "    ]  # Assuming the tensor you want to detach is the first element of the tuple\n",
    "    pred_mask_array = tensor_to_detach.detach().squeeze().cpu().numpy()\n",
    "    pred_mask = np.transpose(pred_mask_array, (1, 2, 0))\n",
    "    gt_mask = np.argmax(gt_mask, axis=2)\n",
    "    pred_mask = np.argmax(pred_mask, axis=2)\n",
    "    classes = np.unique(gt_mask)\n",
    "    for cl in classes:\n",
    "        recall_scores[cl] += recall(gt_mask, pred_mask, cl)\n",
    "        precision_scores[cl] += precision(gt_mask, pred_mask, cl)\n",
    "        f1_scores[cl] += f1_score(gt_mask, pred_mask, cl)\n",
    "        nums[cl] += 1\n",
    "\n",
    "f1_scores = np.array(f1_scores)\n",
    "recall_scores = np.array(recall_scores)\n",
    "precision_scores = np.array(precision_scores)\n",
    "nums = np.array(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Recall Scores per class:\n",
      "        [0.99994141 0.18139851 0.16286149]\n",
      "    Precision Scores per class:\n",
      "        [0.999675   0.25067889 0.16590563]\n",
      "    F1 Scores per class:\n",
      "        [0.99980816 0.19794879 0.15692542]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Recall Scores per class:\n",
    "        {recall_scores / nums}\n",
    "    Precision Scores per class:\n",
    "        {precision_scores / nums}\n",
    "    F1 Scores per class:\n",
    "        {f1_scores / nums}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star-galaxy-classification-qW2-rtF0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
